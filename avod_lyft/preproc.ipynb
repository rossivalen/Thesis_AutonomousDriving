{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import avod\n",
    "from avod.builders.dataset_builder import DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_preprocessing(dataset, indices):\n",
    "\n",
    "    mini_batch_utils = dataset.kitti_utils.mini_batch_utils\n",
    "\n",
    "    print(\"Generating mini batches in {}\".format(\n",
    "        mini_batch_utils.mini_batch_dir))\n",
    "\n",
    "    # Generate all mini-batches, this can take a long time\n",
    "    mini_batch_utils.preprocess_rpn_mini_batches(indices)\n",
    "\n",
    "    print(\"Mini batches generated\")\n",
    "\n",
    "\n",
    "def split_indices(dataset, num_children):\n",
    "    \"\"\"Splits indices between children\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset object\n",
    "        num_children: Number of children to split samples between\n",
    "\n",
    "    Returns:\n",
    "        indices_split: A list of evenly split indices\n",
    "    \"\"\"\n",
    "\n",
    "    all_indices = np.arange(dataset.num_samples)\n",
    "\n",
    "    # Pad indices to divide evenly\n",
    "    length_padding = (-len(all_indices)) % num_children\n",
    "    padded_indices = np.concatenate((all_indices,\n",
    "                                     np.zeros(length_padding,\n",
    "                                              dtype=np.int32)))\n",
    "\n",
    "    # Split and trim last set of indices to original length\n",
    "    indices_split = np.split(padded_indices, num_children)\n",
    "    indices_split[-1] = np.trim_zeros(indices_split[-1])\n",
    "\n",
    "    return indices_split\n",
    "\n",
    "\n",
    "def split_work(all_child_pids, dataset, indices_split, num_children):\n",
    "    \"\"\"Spawns children to do work\n",
    "\n",
    "    Args:\n",
    "        all_child_pids: List of child pids are appended here, the parent\n",
    "            process should use this list to wait for all children to finish\n",
    "        dataset: Dataset object\n",
    "        indices_split: List of indices to split between children\n",
    "        num_children: Number of children\n",
    "    \"\"\"\n",
    "\n",
    "    for child_idx in range(num_children):\n",
    "        new_pid = os.fork()\n",
    "        if new_pid:\n",
    "            all_child_pids.append(new_pid)\n",
    "        else:\n",
    "            indices = indices_split[child_idx]\n",
    "            print('child', dataset.classes,\n",
    "                  indices_split[child_idx][0],\n",
    "                  indices_split[child_idx][-1])\n",
    "            do_preprocessing(dataset, indices)\n",
    "            os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset=None):\n",
    "    \"\"\"Generates anchors info which is used for mini batch sampling.\n",
    "\n",
    "    Processing on 'Cars' can be split into multiple processes, see the Options\n",
    "    section for configuration.\n",
    "\n",
    "    Args:\n",
    "        dataset: KittiDataset (optional)\n",
    "            If dataset is provided, only generate info for that dataset.\n",
    "            If no dataset provided, generates info for all 3 classes.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is not None:\n",
    "        do_preprocessing(dataset, None)\n",
    "        return\n",
    "\n",
    "    car_dataset_config_path = avod.root_dir() + \\\n",
    "        '/configs/mb_preprocessing/rpn_cars.config'\n",
    "    ped_dataset_config_path = avod.root_dir() + \\\n",
    "        '/configs/mb_preprocessing/rpn_pedestrians.config'\n",
    "    cyc_dataset_config_path = avod.root_dir() + \\\n",
    "        '/configs/mb_preprocessing/rpn_cyclists.config'\n",
    "    ppl_dataset_config_path = avod.root_dir() + \\\n",
    "        '/configs/mb_preprocessing/rpn_people.config'\n",
    "\n",
    "    ##############################\n",
    "    # Options\n",
    "    ##############################\n",
    "    # Serial vs parallel processing\n",
    "    in_parallel = True\n",
    "\n",
    "    process_car = True   # Cars\n",
    "    process_ped = False  # Pedestrians\n",
    "    process_cyc = False  # Cyclists\n",
    "    process_ppl = True   # People (Pedestrians + Cyclists)\n",
    "\n",
    "    # Number of child processes to fork, samples will\n",
    "    #  be divided evenly amongst the processes (in_parallel must be True)\n",
    "    num_car_children = 8\n",
    "    num_ped_children = 8\n",
    "    num_cyc_children = 8\n",
    "    num_ppl_children = 8\n",
    "\n",
    "    ##############################\n",
    "    # Dataset setup\n",
    "    ##############################\n",
    "    if process_car:\n",
    "        car_dataset = DatasetBuilder.load_dataset_from_config(\n",
    "            car_dataset_config_path)\n",
    "    if process_ped:\n",
    "        ped_dataset = DatasetBuilder.load_dataset_from_config(\n",
    "            ped_dataset_config_path)\n",
    "    if process_cyc:\n",
    "        cyc_dataset = DatasetBuilder.load_dataset_from_config(\n",
    "            cyc_dataset_config_path)\n",
    "    if process_ppl:\n",
    "        ppl_dataset = DatasetBuilder.load_dataset_from_config(\n",
    "            ppl_dataset_config_path)\n",
    "\n",
    "    ##############################\n",
    "    # Serial Processing\n",
    "    ##############################\n",
    "    if not in_parallel:\n",
    "        if process_car:\n",
    "            do_preprocessing(car_dataset, None)\n",
    "        if process_ped:\n",
    "            do_preprocessing(ped_dataset, None)\n",
    "        if process_cyc:\n",
    "            do_preprocessing(cyc_dataset, None)\n",
    "        if process_ppl:\n",
    "            do_preprocessing(ppl_dataset, None)\n",
    "\n",
    "        print('All Done (Serial)')\n",
    "\n",
    "    ##############################\n",
    "    # Parallel Processing\n",
    "    ##############################\n",
    "    else:\n",
    "\n",
    "        # List of all child pids to wait on\n",
    "        all_child_pids = []\n",
    "\n",
    "        # Cars\n",
    "        if process_car:\n",
    "            car_indices_split = split_indices(car_dataset, num_car_children)\n",
    "            split_work(\n",
    "                all_child_pids,\n",
    "                car_dataset,\n",
    "                car_indices_split,\n",
    "                num_car_children)\n",
    "\n",
    "        # Pedestrians\n",
    "        if process_ped:\n",
    "            ped_indices_split = split_indices(ped_dataset, num_ped_children)\n",
    "            split_work(\n",
    "                all_child_pids,\n",
    "                ped_dataset,\n",
    "                ped_indices_split,\n",
    "                num_ped_children)\n",
    "\n",
    "        # Cyclists\n",
    "        if process_cyc:\n",
    "            cyc_indices_split = split_indices(cyc_dataset, num_cyc_children)\n",
    "            split_work(\n",
    "                all_child_pids,\n",
    "                cyc_dataset,\n",
    "                cyc_indices_split,\n",
    "                num_cyc_children)\n",
    "\n",
    "        # People (Pedestrians + Cyclists)\n",
    "        if process_ppl:\n",
    "            ppl_indices_split = split_indices(ppl_dataset, num_ppl_children)\n",
    "            split_work(\n",
    "                all_child_pids,\n",
    "                ppl_dataset,\n",
    "                ppl_indices_split,\n",
    "                num_ppl_children)\n",
    "\n",
    "        # Wait to child processes to finish\n",
    "        print('num children:', len(all_child_pids))\n",
    "        for i, child_pid in enumerate(all_child_pids):\n",
    "            os.waitpid(child_pid, 0)\n",
    "\n",
    "        print('All Done (Parallel)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
