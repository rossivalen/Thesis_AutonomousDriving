{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will have to change the filenames, i.e from kitti_utils to a more general name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import avod\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from avod.builders.dataset_builder import DatasetBuilder\n",
    "from avod.core.mini_batch_utils import MiniBatchUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "15991 instance,\n",
      "8 sensor,\n",
      "128 calibrated_sensor,\n",
      "149072 ego_pose,\n",
      "148 log,\n",
      "148 scene,\n",
      "18634 sample,\n",
      "149072 sample_data,\n",
      "539765 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 15.4 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 4.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "DATASET_VERSION = 'v1.02-train'\n",
    "DATASET_ROOT = '../../nuscenes-devkit/data/'\n",
    "\n",
    "level5data = LyftDataset(json_path=DATASET_ROOT + \"/v1.02-train\", data_path=DATASET_ROOT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other_vehicle',\n",
       " 'animal',\n",
       " 'truck',\n",
       " 'car',\n",
       " 'bus',\n",
       " 'emergency_vehicle',\n",
       " 'pedestrian',\n",
       " 'motorcycle',\n",
       " 'bicycle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes=[]\n",
    "for i in level5data.category:\n",
    "    classes.append(i.get(\"name\"))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_preprocessing(dataset, indices):\n",
    "    \n",
    "    mini_batch_utils = MiniBatchUtils(dataset)\n",
    "    print(\"Generating mini batches in {}\".format(mini_batch_utils.avod_iou_type))\n",
    "\n",
    "    # Generate all mini-batches, this can take a long time\n",
    "    mini_batch_utils.preprocess_rpn_mini_batches(dataset, indices)\n",
    "\n",
    "    print(\"Mini batches generated\")\n",
    "\n",
    "\n",
    "def split_indices(dataset, num_children):\n",
    "    \"\"\"Splits indices between children\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset object\n",
    "        num_children: Number of children to split samples between\n",
    "\n",
    "    Returns:\n",
    "        indices_split: A list of evenly split indices\n",
    "    \"\"\"\n",
    "\n",
    "    all_indices = np.arange(dataset.num_samples)\n",
    "\n",
    "    # Pad indices to divide evenly\n",
    "    length_padding = (-len(all_indices)) % num_children\n",
    "    padded_indices = np.concatenate((all_indices,\n",
    "                                     np.zeros(length_padding,\n",
    "                                              dtype=np.int32)))\n",
    "\n",
    "    # Split and trim last set of indices to original length\n",
    "    indices_split = np.split(padded_indices, num_children)\n",
    "    indices_split[-1] = np.trim_zeros(indices_split[-1])\n",
    "\n",
    "    return indices_split\n",
    "\n",
    "\n",
    "def split_work(all_child_pids, dataset, indices_split, num_children):\n",
    "    \"\"\"Spawns children to do work\n",
    "\n",
    "    Args:\n",
    "        all_child_pids: List of child pids are appended here, the parent\n",
    "            process should use this list to wait for all children to finish\n",
    "        dataset: Dataset object\n",
    "        indices_split: List of indices to split between children\n",
    "        num_children: Number of children\n",
    "    \"\"\"\n",
    "\n",
    "    for child_idx in range(num_children):\n",
    "        new_pid = os.fork()\n",
    "        if new_pid:\n",
    "            all_child_pids.append(new_pid)\n",
    "        else:\n",
    "            indices = indices_split[child_idx]\n",
    "            print('child', dataset.classes,\n",
    "                  indices_split[child_idx][0],\n",
    "                  indices_split[child_idx][-1])\n",
    "            do_preprocessing(dataset, indices)\n",
    "            os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generates anchors info which is used for mini batch sampling.\n",
    "\n",
    "Processing on 'Cars' can be split into multiple processes, see the Options\n",
    "section for configuration.\n",
    "\n",
    "Args:\n",
    "dataset: KittiDataset (optional)\n",
    "    If dataset is provided, only generate info for that dataset.\n",
    "    If no dataset provided, generates info for all 3 classes.\n",
    "\"\"\"\n",
    "\n",
    "# if level5data is not None:\n",
    "# do_preprocessing(level5data, None)\n",
    "# return\n",
    "\n",
    "car_dataset_config_path = avod.root_dir() + \\\n",
    "'/configs/mb_preprocessing/rpn_cars.config'\n",
    "ped_dataset_config_path = avod.root_dir() + \\\n",
    "'/configs/mb_preprocessing/rpn_pedestrians.config'\n",
    "cyc_dataset_config_path = avod.root_dir() + \\\n",
    "'/configs/mb_preprocessing/rpn_cyclists.config'\n",
    "ppl_dataset_config_path = avod.root_dir() + \\\n",
    "'/configs/mb_preprocessing/rpn_people.config'\n",
    "\n",
    "##############################\n",
    "# Options\n",
    "##############################\n",
    "# Serial vs parallel processing\n",
    "in_parallel = True\n",
    "\n",
    "process_car = True   # Cars\n",
    "process_ped = False  # Pedestrians\n",
    "process_cyc = False  # Cyclists\n",
    "process_ppl = True   # People (Pedestrians + Cyclists)\n",
    "\n",
    "# Number of child processes to fork, samples will\n",
    "#  be divided evenly amongst the processes (in_parallel must be True)\n",
    "num_car_children = 8\n",
    "num_ped_children = 8\n",
    "num_cyc_children = 8\n",
    "num_ppl_children = 8\n",
    "\n",
    "##############################\n",
    "# Dataset setup\n",
    "##############################\n",
    "#car_dataset = DatasetBuilder.load_dataset_from_config( car_dataset_config_path, level5data)\n",
    "#ppl_dataset = DatasetBuilder.load_dataset_from_config( ppl_dataset_config_path, level5data)\n",
    "\n",
    "print(\"done clustering!! yay\")\n",
    "\n",
    "#############################\n",
    "# Serial Processing\n",
    "#############################\n",
    "#if not in_parallel:\n",
    "print(\"start processing..\")\n",
    "do_preprocessing(level5data, None)\n",
    "\n",
    "print('All Done (Serial) :)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31a4d8a41fe1d1cba56913c850eaf0c6060dc459dd464ff9b5f6df350a34b8c7 G:\\lyft\\nuscenes-devkit\\avod_lyft\\..\\..\\nuscenes-devkit\\data\\lidar\\host-a011_lidar1_1233963416301269366.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.8625122e+01,  7.7645058e+01,  7.6680885e+01, ...,\n",
       "         5.8347611e+00,  5.8272061e+00,  5.8465562e+00],\n",
       "       [ 1.5347293e+01,  1.5437528e+01,  1.5524225e+01, ...,\n",
       "        -5.2094843e-02, -3.0677900e-02, -1.0382481e-02],\n",
       "       [ 1.0349571e+01,  1.0227524e+01,  1.0107526e+01, ...,\n",
       "        -1.6039984e+00, -1.6018642e+00, -1.6072005e+00],\n",
       "       [ 1.0000000e+02,  1.0000000e+02,  1.0000000e+02, ...,\n",
       "         1.0000000e+02,  1.0000000e+02,  1.0000000e+02]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud\n",
    "my_scene = level5data.scene[5]\n",
    "my_sample_token = my_scene[\"first_sample_token\"]\n",
    "sample = level5data.get('sample', my_sample_token)\n",
    "sample_name = sample.get(\"token\")\n",
    "my_sample_data = level5data.get('sample_data', sample['data'][\"LIDAR_TOP\"])\n",
    "tok = my_sample_data.get(\"sample_token\")\n",
    "print(bev_token, lidar_filepath)\n",
    "bev_token= my_sample_data.get(\"token\")\n",
    "lidar_filepath =level5data.get_sample_data_path(bev_token)\n",
    "lidar_pointcloud = LidarPointCloud.from_file(lidar_filepath)\n",
    "lidar_pointcloud.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
